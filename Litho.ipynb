{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import  RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import  XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../bayseg/\")\n",
    "import bayseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold , StratifiedKFold\n",
    "from classification_utilities import display_cm, display_adj_cm\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.signal import medfilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load Data\n",
    "data = pd.read_csv(\"../bayseg/data/2016-ml-contest-Hall/Nomalised_data.csv\")\n",
    "\n",
    "# Parameters\n",
    "feature_names = ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND', 'PE', 'NM_M', 'RELPOS']\n",
    "facies_names = ['SS', 'CSiS', 'FSiS', 'SiSh', 'MS', 'WS', 'D', 'PS', 'BS']\n",
    "facies_colors = ['#F4D03F', '#F5B041','#DC7633','#6E2C00', '#1B4F72','#2E86C1', '#AED6F1', '#A569BD', '#196F3D']\n",
    "\n",
    "# Store features and labels\n",
    "X = data[feature_names].values \n",
    "y = data['Facies'].values \n",
    "\n",
    "# Store well labels and depths\n",
    "well = data['Well Name'].values\n",
    "depth = data['Depth'].values\n",
    "\n",
    "# Fill 'PE' missing values with mean\n",
    "imp = preprocessing.Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "imp.fit(X)\n",
    "X = imp.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Feature windows concatenation function\n",
    "def augment_features_window(X, N_neig):\n",
    "    \n",
    "    # Parameters\n",
    "    N_row = X.shape[0]\n",
    "    N_feat = X.shape[1]\n",
    "\n",
    "    # Zero padding\n",
    "    X = np.vstack((np.zeros((N_neig, N_feat)), X, (np.zeros((N_neig, N_feat)))))\n",
    "\n",
    "    # Loop over windows\n",
    "    X_aug = np.zeros((N_row, N_feat*(2*N_neig+1)))\n",
    "    for r in np.arange(N_row)+N_neig:\n",
    "        this_row = []\n",
    "        for c in np.arange(-N_neig,N_neig+1):\n",
    "            this_row = np.hstack((this_row, X[r+c]))\n",
    "        X_aug[r-N_neig] = this_row\n",
    "\n",
    "    return X_aug\n",
    "\n",
    "\n",
    "# Feature gradient computation function\n",
    "def augment_features_gradient(X, depth):\n",
    "    \n",
    "    # Compute features gradient\n",
    "    d_diff = np.diff(depth).reshape((-1, 1))\n",
    "    d_diff[d_diff==0] = 0.001\n",
    "    X_diff = np.diff(X, axis=0)\n",
    "    X_grad = X_diff / d_diff\n",
    "        \n",
    "    # Compensate for last missing value\n",
    "    X_grad = np.concatenate((X_grad, np.zeros((1, X_grad.shape[1]))))\n",
    "    \n",
    "    return X_grad\n",
    "\n",
    "\n",
    "# Feature augmentation function\n",
    "def augment_features(X, well, depth, N_neig=1):\n",
    "    \n",
    "    # Augment features\n",
    "    X_aug = np.zeros((X.shape[0], X.shape[1]*(N_neig*2+2)))\n",
    "    for w in np.unique(well):\n",
    "        w_idx = np.where(well == w)[0]\n",
    "        X_aug_win = augment_features_window(X[w_idx, :], N_neig)\n",
    "        X_aug_grad = augment_features_gradient(X[w_idx, :], depth[w_idx])\n",
    "        X_aug[w_idx, :] = np.concatenate((X_aug_win, X_aug_grad), axis=1)\n",
    "    \n",
    "    # Find padded rows\n",
    "    padded_rows = np.unique(np.where(X_aug[:, 0:7] == np.zeros((1, 7)))[0])\n",
    "    \n",
    "    return X_aug, padded_rows\n",
    "\n",
    "X_aug, padded_rows = augment_features(X, well, depth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model selection methods\n",
    "lpgo = LeavePGroupsOut(2)\n",
    "\n",
    "# Generate splits\n",
    "split_list = []\n",
    "for train, val in lpgo.split(X, y, groups=data['Well Name']):\n",
    "    hist_tr = np.histogram(y[train], bins=np.arange(len(facies_names)+1)+.5)\n",
    "    hist_val = np.histogram(y[val], bins=np.arange(len(facies_names)+1)+.5)\n",
    "    if np.all(hist_tr[0] != 0) & np.all(hist_val[0] != 0):\n",
    "        split_list.append({'train':train, 'val':val})\n",
    "    \n",
    "        \n",
    "def preprocess():\n",
    "    \n",
    "    # Preprocess data to use in model\n",
    "    X_train_aux = []\n",
    "    X_test_aux = []\n",
    "    y_train_aux = []\n",
    "    y_test_aux = []\n",
    "    \n",
    "    # For each data split\n",
    "    split = split_list[5]\n",
    "        \n",
    "    # Remove padded rows\n",
    "    split_train_no_pad = np.setdiff1d(split['train'], padded_rows)\n",
    "\n",
    "    # Select training and validation data from current split\n",
    "    X_tr = X_aug[split_train_no_pad, :]\n",
    "    X_v = X_aug[split['val'], :]\n",
    "    y_tr = y[split_train_no_pad]\n",
    "    y_v = y[split['val']]\n",
    "\n",
    "    # Select well labels for validation data\n",
    "    well_v = well[split['val']]\n",
    "\n",
    "    # Feature normalization\n",
    "    scaler = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_tr)\n",
    "    X_tr = scaler.transform(X_tr)\n",
    "    X_v = scaler.transform(X_v)\n",
    "        \n",
    "    X_train_aux.append( X_tr )\n",
    "    X_test_aux.append( X_v )\n",
    "    y_train_aux.append( y_tr )\n",
    "    y_test_aux.append (  y_v )\n",
    "    \n",
    "    X_train = np.concatenate( X_train_aux )\n",
    "    X_test = np.concatenate ( X_test_aux )\n",
    "    y_train = np.concatenate ( y_train_aux )\n",
    "    y_test = np.concatenate ( y_test_aux )\n",
    "    \n",
    "    return X_train , X_test , y_train , y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CGRE-HiWi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\deap\\creator.py:141: RuntimeWarning: A class named 'FitnessMulti' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "C:\\Users\\CGRE-HiWi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\deap\\creator.py:141: RuntimeWarning: A class named 'Individual' has already been created and it will be overwritten. Consider deleting previous creation of that class or rename it.\n",
      "  RuntimeWarning)\n",
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.7218305242872587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 2 - Current best internal CV score: 0.7300345458158001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3 - Current best internal CV score: 0.7300345458158001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 4 - Current best internal CV score: 0.7423646122500995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 5 - Current best internal CV score: 0.7500588276598688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 6 - Current best internal CV score: 0.7500588276598688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 7 - Current best internal CV score: 0.7516465335421076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 8 - Current best internal CV score: 0.759535838891402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 9 - Current best internal CV score: 0.759535838891402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best pipeline: RandomForestClassifier(XGBClassifier(GaussianNB(input_matrix), learning_rate=0.1, max_depth=6, min_child_weight=2, n_estimators=100, nthread=1, subsample=0.75), bootstrap=True, criterion=gini, max_features=0.2, min_samples_leaf=5, min_samples_split=11, n_estimators=100)\n",
      "0.767123287671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = preprocess()\n",
    "\n",
    "tpot = TPOTClassifier(generations=5, population_size=20, \n",
    "                      verbosity=2,max_eval_time_mins=20,\n",
    "                      max_time_mins=100,scoring='f1_micro',\n",
    "                      random_state = 17)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_test, y_test))\n",
    "tpot.export('FinalPipeline.py') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import  RandomForestClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import  XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train and test a classifier\n",
    "def train_and_test(X_tr, y_tr, X_v, well_v):\n",
    "    \n",
    "    # Feature normalization\n",
    "    scaler = preprocessing.RobustScaler(quantile_range=(25.0, 75.0)).fit(X_tr)\n",
    "    X_tr = scaler.transform(X_tr)\n",
    "    X_v = scaler.transform(X_v)\n",
    "    \n",
    "    # Train classifier\n",
    "    #clf = make_pipeline(make_union(VotingClassifier([(\"est\", ExtraTreesClassifier(criterion=\"gini\", max_features=1.0, n_estimators=500))]), FunctionTransformer(lambda X: X)), XGBClassifier(learning_rate=0.73, max_depth=10, min_child_weight=10, n_estimators=500, subsample=0.27))\n",
    "    #clf =  make_pipeline( KNeighborsClassifier(n_neighbors=5, weights=\"distance\") ) \n",
    "    #clf = make_pipeline(MaxAbsScaler(),make_union(VotingClassifier([(\"est\", RandomForestClassifier(n_estimators=500))]), FunctionTransformer(lambda X: X)),ExtraTreesClassifier(criterion=\"entropy\", max_features=0.0001, n_estimators=500))\n",
    "    # * clf = make_pipeline( make_union(VotingClassifier([(\"est\", BernoulliNB(alpha=60.0, binarize=0.26, fit_prior=True))]), FunctionTransformer(lambda X: X)),RandomForestClassifier(n_estimators=500))\n",
    "    clf = make_pipeline ( XGBClassifier(learning_rate=0.12, max_depth=3, min_child_weight=10, n_estimators=150, seed = 17, colsample_bytree = 0.9) )\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    \n",
    "    # Test classifier\n",
    "    y_v_hat = clf.predict(X_v)\n",
    "    \n",
    "    # Clean isolated facies for each well\n",
    "    for w in np.unique(well_v):\n",
    "        y_v_hat[well_v==w] = medfilt(y_v_hat[well_v==w], kernel_size=5)\n",
    "    \n",
    "    return y_v_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Load testing data\n",
    "test_data = pd.read_csv(\"../bayseg/data/2016-ml-contest-Hall/test_data_new.csv\")\n",
    "\n",
    "# Prepare training data\n",
    "X_tr = X\n",
    "y_tr = y\n",
    "\n",
    "# Augment features\n",
    "X_tr, padded_rows = augment_features(X_tr, well, depth)\n",
    "\n",
    "# Removed padded rows\n",
    "X_tr = np.delete(X_tr, padded_rows, axis=0)\n",
    "y_tr = np.delete(y_tr, padded_rows, axis=0) \n",
    "\n",
    "# Prepare test data\n",
    "well_ts = test_data['Well Name'].values\n",
    "depth_ts = test_data['Depth'].values\n",
    "X_ts = test_data[feature_names].values\n",
    "\n",
    "# Augment features\n",
    "X_ts, padded_rows = augment_features(X_ts, well_ts, depth_ts)\n",
    "\n",
    "# Predict test labels\n",
    "y_ts_hat = train_and_test(X_tr, y_tr, X_ts, well_ts)\n",
    "\n",
    "# Save predicted labels\n",
    "test_data['Facies'] = y_ts_hat\n",
    "test_data.to_csv('Prediction_XX_Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# predict_data = pd.read_csv(\"Prediction_XX_Final.csv\")\n",
    "# result = data[data[\"Well Name\"] == \"SHRIMPLIN\"][\"Facies\"]\n",
    "# print(predict_data[\"Facies\"].values)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sol = np.repeat(np.expand_dims(predict_data[\"Facies\"].values, 1), 100, 1)\n",
    "# ml_sol = np.repeat(np.expand_dims(result, 1), 100, 1)\n",
    "\n",
    "# fig, ax = plt.subplots(ncols=2, sharey=True, figsize=(2,13))\n",
    "\n",
    "# ax[0].imshow(sol, cmap=\"viridis\")\n",
    "# ax[1].imshow(ml_sol, cmap=\"viridis\")\n",
    "\n",
    "# np.count_nonzero(sol[:,1]-ml_sol[:,1])\n",
    "\n",
    "# ax[0].grid(False)\n",
    "# ax[1].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy.stats\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../bayseg\")\n",
    "import bayseg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CGRE-HiWi\\Documents\\bayseg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "print(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../bayseg/data/2016-ml-contest-Hall/Nomalised_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_feature_vectors(feature_vectors):\n",
    "    return (feature_vectors - np.mean(feature_vectors, axis=0).T) / np.std(feature_vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names =  ['GR', 'ILD_log10', 'DeltaPHI', 'PHIND','PE']\n",
    "feature_vectors = data[feature_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coords = np.array([data[\"Depth\"].values]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_vectors_norm = normalize_feature_vectors(feature_vectors.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEXCAYAAACkpJNEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20fb057c6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "global minimum:  8\n"
     ]
    }
   ],
   "source": [
    "bayseg.bic(feature_vectors_norm, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = bayseg.BaySeg(feature_vectors_norm, n_labels=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3231, 23)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▋                                                                                 | 2/250 [00:04<08:17,  2.01s/it]C:\\Users\\CGRE-HiWi\\Documents\\bayseg\\bayseg\\bayseg.py:873: RuntimeWarning: overflow encountered in exp\n",
      "  ratio = np.exp(np.longfloat(log_target_prop - log_target_prev))\n",
      "  2%|█▎                                                                                | 4/250 [00:08<08:12,  2.00s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-136-533ddffd199c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mmu_jump_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0005\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mcov_volume_jump_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.00005\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         theta_jump_length=0.0000005, verbose=False)\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\bayseg\\bayseg\\bayseg.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, n, beta_jump_length, mu_jump_length, cov_volume_jump_length, theta_jump_length, t, verbose, fix_beta)\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             self.gibbs_sample(t, beta_jump_length, mu_jump_length, cov_volume_jump_length, theta_jump_length,\n\u001b[1;32m--> 191\u001b[1;33m                               verbose, fix_beta)\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m     def gibbs_sample(self, t, beta_jump_length, mu_jump_length, cov_volume_jump_length, theta_jump_length, verbose,\n",
      "\u001b[1;32m~\\Documents\\bayseg\\bayseg\\bayseg.py\u001b[0m in \u001b[0;36mgibbs_sample\u001b[1;34m(self, t, beta_jump_length, mu_jump_length, cov_volume_jump_length, theta_jump_length, verbose, fix_beta)\u001b[0m\n\u001b[0;32m    316\u001b[0m             \u001b[1;31m# print(\"lp_cov_prop:\", lp_cov_prop)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 318\u001b[1;33m             \u001b[0mlmd_prev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalc_sum_log_mixture_density\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcomp_coef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu_next\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov_next\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m             \u001b[1;31m# print(\"lmd_prev:\", lmd_prev)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m             \u001b[1;31m# calculate log mixture density for proposed mu and cov\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\bayseg\\bayseg\\bayseg.py\u001b[0m in \u001b[0;36mcalc_sum_log_mixture_density\u001b[1;34m(self, comp_coef, mu, cov)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m             \u001b[0mdraw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmultivariate_normal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmu\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcov\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcov\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m             \u001b[1;31m# print(np.shape(lmd[:,l]))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m             \u001b[0mmulti\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomp_coef\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\scipy\\stats\\_multivariate.py\u001b[0m in \u001b[0;36mpdf\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    608\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    609\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 610\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogpdf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    611\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrvs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf.fit(250, \n",
    "        beta_jump_length=2,  \n",
    "        mu_jump_length=0.0005, \n",
    "        cov_volume_jump_length=0.00005, \n",
    "        theta_jump_length=0.0000005, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_facie = pd.read_csv(\"Prediction_XX_Final.csv\")[\"Facies\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415,)"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_facie.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(415,)"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indeces = np.where(data[\"Well Name\"] == \"NOLAN\")[0]\n",
    "test_data = data[data[\"Well Name\"] == \"NOLAN\"]\n",
    "\n",
    "seg = clf.labels[-1][indeces]\n",
    "seg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0.,    0.,    0.,    1.,    1.,    1.,    2.,    3.,    4.,\n",
       "          5.,    6.,    7.,    8.,    8.,    8.,    9.,    9.,    9.,\n",
       "         10.,   10.,   10.,   10.,   11.,   11.,   12.,   13.,   13.,\n",
       "         13.,   14.,   14.,   14.,   14.,   14.,   14.,   14.,   15.,\n",
       "         16.,   16.,   17.,   18.,   19.,   19.,   19.,   20.,   20.,\n",
       "         20.,   20.,   21.,   22.,   23.,   23.,   24.,   25.,   25.,\n",
       "         25.,   25.,   26.,   27.,   28.,   29.,   29.,   30.,   30.,\n",
       "         30.,   30.,   30.,   30.,   31.,   31.,   32.,   33.,   33.,\n",
       "         34.,   34.,   35.,   35.,   36.,   37.,   38.,   38.,   38.,\n",
       "         38.,   38.,   39.,   39.,   39.,   39.,   40.,   40.,   41.,\n",
       "         42.,   43.,   44.,   45.,   45.,   45.,   45.,   46.,   47.,\n",
       "         48.,   48.,   49.,   49.,   49.,   50.,   51.,   51.,   52.,\n",
       "         52.,   52.,   52.,   53.,   54.,   54.,   54.,   55.,   55.,\n",
       "         56.,   57.,   57.,   57.,   58.,   58.,   58.,   58.,   58.,\n",
       "         58.,   58.,   58.,   58.,   58.,   59.,   59.,   60.,   60.,\n",
       "         60.,   60.,   61.,   62.,   63.,   64.,   64.,   64.,   64.,\n",
       "         64.,   65.,   65.,   65.,   65.,   66.,   66.,   67.,   67.,\n",
       "         68.,   69.,   69.,   70.,   70.,   70.,   70.,   70.,   71.,\n",
       "         71.,   72.,   72.,   72.,   72.,   72.,   73.,   74.,   74.,\n",
       "         75.,   75.,   76.,   76.,   77.,   77.,   78.,   78.,   79.,\n",
       "         79.,   79.,   79.,   79.,   79.,   79.,   79.,   80.,   80.,\n",
       "         80.,   80.,   80.,   80.,   81.,   82.,   83.,   83.,   84.,\n",
       "         85.,   86.,   86.,   86.,   86.,   87.,   87.,   87.,   87.,\n",
       "         87.,   87.,   88.,   88.,   89.,   89.,   89.,   90.,   90.,\n",
       "         91.,   92.,   92.,   93.,   93.,   94.,   95.,   95.,   96.,\n",
       "         97.,   98.,   98.,   99.,   99.,   99.,   99.,  100.,  100.,\n",
       "        100.,  101.,  101.,  101.,  102.,  102.,  102.,  102.,  102.,\n",
       "        102.,  103.,  104.,  105.,  106.,  106.,  106.,  106.,  106.,\n",
       "        106.,  106.,  106.,  106.,  106.,  107.,  107.,  108.,  109.,\n",
       "        110.,  111.,  111.,  112.,  113.,  113.,  114.,  115.,  115.,\n",
       "        115.,  115.,  116.,  117.,  118.,  119.,  120.,  121.,  121.,\n",
       "        122.,  123.,  123.,  123.,  123.,  123.,  123.,  123.,  123.,\n",
       "        123.,  123.,  123.,  123.,  123.,  123.,  123.,  123.,  123.,\n",
       "        123.,  123.,  123.,  123.,  123.,  123.,  123.,  124.,  124.,\n",
       "        124.,  124.,  125.,  126.,  127.,  127.,  128.,  129.,  130.,\n",
       "        130.,  131.,  132.,  133.,  133.,  133.,  133.,  134.,  134.,\n",
       "        134.,  134.,  134.,  135.,  135.,  135.,  135.,  136.,  136.,\n",
       "        137.,  138.,  139.,  139.,  139.,  140.,  140.,  141.,  141.,\n",
       "        141.,  141.,  141.,  141.,  141.,  141.,  142.,  142.,  143.,\n",
       "        144.,  145.,  145.,  145.,  145.,  145.,  145.,  145.,  145.,\n",
       "        145.,  146.,  146.,  146.,  146.,  146.,  146.,  147.,  148.,\n",
       "        148.,  148.,  149.,  150.,  151.,  151.,  151.,  151.,  151.,\n",
       "        151.,  152.,  152.,  152.,  152.,  152.,  152.,  153.,  153.,\n",
       "        153.,  153.,  154.,  155.,  155.,  156.,  157.,  157.,  157.,\n",
       "        157.,  157.,  158.,  159.,  159.,  159.,  160.,  160.,  160.,\n",
       "        160.,  160.,  161.,  161.,  162.,  163.,  164.,  164.,  164.,  164.])"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_seg = np.zeros(shape = (len(seg),))\n",
    "for i in range(0, len(seg)):\n",
    "    if i == 0:\n",
    "        new_seg[i] = 0\n",
    "    elif seg[i] == seg[i-1]:\n",
    "        new_seg[i] = new_seg[i-1]+0\n",
    "    elif seg[i] != seg[i-1]:\n",
    "        new_seg[i] = new_seg[i-1]+1 \n",
    "new_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare = np.vstack((predict_facie, new_seg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   3.,    3.,    3.,    3.,    3.,    3.,    3.,    3.,    3.,\n",
       "           3.,    3.,    3.,    3.,    3.,    3.,    2.,    2.,    2.,\n",
       "           2.,    2.,    1.,    1.,    1.,    1.,    1.,    2.,    2.,\n",
       "           2.,    2.,    2.,    2.,    2.,    1.,    1.,    1.,    1.,\n",
       "           1.,    1.,    3.,    3.,    3.,    3.,    3.,    3.,    5.,\n",
       "           5.,    5.,    8.,    8.,    8.,    8.,    6.,    6.,    6.,\n",
       "           5.,    5.,    5.,    5.,    5.,    5.,    5.,    6.,    6.,\n",
       "           7.,    7.,    7.,    7.,    9.,    9.,    9.,    8.,    6.,\n",
       "           6.,    6.,    6.,    6.,    6.,    6.,    6.,    6.,    6.,\n",
       "           7.,    8.,    8.,    8.,    8.,    7.,    7.,    7.,    8.,\n",
       "           8.,    8.,    8.,    7.,    6.,    6.,    6.,    6.,    6.,\n",
       "           6.,    6.,    6.,    6.,    4.,    3.,    3.,    3.,    3.,\n",
       "           3.,    3.,    3.,    3.,    3.,    3.,    3.,    3.,    3.,\n",
       "           3.,    3.,    2.,    2.,    2.,    2.,    2.,    2.,    2.,\n",
       "           1.,    1.,    1.,    2.,    1.,    1.,    3.,    3.,    3.,\n",
       "           3.,    3.,    8.,    8.,    8.,    8.,    8.,    8.,    8.,\n",
       "           8.,    8.,    8.,    8.,    8.,    4.,    4.,    4.,    4.,\n",
       "           6.,    6.,    6.,    6.,    4.,    3.,    3.,    2.,    2.,\n",
       "           2.,    2.,    2.,    3.,    3.,    3.,    3.,    3.,    3.,\n",
       "           3.,    2.,    2.,    2.,    2.,    2.,    3.,    3.,    3.,\n",
       "           8.,    8.,    8.,    8.,    8.,    8.,    8.,    8.,    8.,\n",
       "           8.,    8.,    8.,    8.,    8.,    8.,    8.,    8.,    6.,\n",
       "           6.,    6.,    6.,    6.,    6.,    6.,    3.,    3.,    2.,\n",
       "           2.,    2.,    2.,    2.,    2.,    2.,    2.,    2.,    2.,\n",
       "           2.,    2.,    2.,    3.,    2.,    2.,    2.,    2.,    2.,\n",
       "           2.,    2.,    2.,    2.,    3.,    5.,    8.,    8.,    8.,\n",
       "           8.,    8.,    8.,    8.,    8.,    8.,    8.,    8.,    2.,\n",
       "           2.,    2.,    2.,    2.,    2.,    2.,    2.,    2.,    2.,\n",
       "           2.,    2.,    2.,    2.,    2.,    2.,    2.,    2.,    2.,\n",
       "           3.,    3.,    3.,    3.,    3.,    8.,    8.,    8.,    8.,\n",
       "           8.,    6.,    5.,    5.,    5.,    4.,    3.,    3.,    3.,\n",
       "           3.,    3.,    3.,    3.,    3.,    8.,    8.,    8.,    8.,\n",
       "           8.,    8.,    8.,    8.,    8.,    8.,    8.,    8.,    8.,\n",
       "           8.,    8.,    8.,    8.,    8.,    7.,    8.,    7.,    7.,\n",
       "           7.,    7.,    5.,    5.,    5.,    6.,    6.,    7.,    7.,\n",
       "           7.,    7.,    7.,    6.,    6.,    3.,    3.,    3.,    3.,\n",
       "           3.,    3.,    3.,    3.,    3.,    3.,    3.,    3.,    3.,\n",
       "           3.,    3.,    3.,    3.,    3.,    3.,    3.,    3.,    2.,\n",
       "           2.,    2.,    2.,    2.,    2.,    2.,    2.,    2.,    2.,\n",
       "           2.,    2.,    2.,    2.,    3.,    3.,    3.,    8.,    8.,\n",
       "           8.,    8.,    8.,    8.,    8.,    5.,    5.,    5.,    5.,\n",
       "           5.,    5.,    5.,    6.,    6.,    6.,    6.,    5.,    5.,\n",
       "           5.,    5.,    5.,    5.,    5.,    5.,    5.,    5.,    5.,\n",
       "           5.,    5.,    5.,    5.,    5.,    5.,    6.,    6.,    6.,\n",
       "           6.,    8.,    8.,    8.,    8.,    8.,    5.,    5.,    5.,\n",
       "           5.,    5.,    5.,    5.,    5.,    5.,    5.,    5.,    5.,\n",
       "           5.],\n",
       "       [   0.,    0.,    0.,    1.,    1.,    1.,    2.,    3.,    4.,\n",
       "           5.,    6.,    7.,    8.,    8.,    8.,    9.,    9.,    9.,\n",
       "          10.,   10.,   10.,   10.,   11.,   11.,   12.,   13.,   13.,\n",
       "          13.,   14.,   14.,   14.,   14.,   14.,   14.,   14.,   15.,\n",
       "          16.,   16.,   17.,   18.,   19.,   19.,   19.,   20.,   20.,\n",
       "          20.,   20.,   21.,   22.,   23.,   23.,   24.,   25.,   25.,\n",
       "          25.,   25.,   26.,   27.,   28.,   29.,   29.,   30.,   30.,\n",
       "          30.,   30.,   30.,   30.,   31.,   31.,   32.,   33.,   33.,\n",
       "          34.,   34.,   35.,   35.,   36.,   37.,   38.,   38.,   38.,\n",
       "          38.,   38.,   39.,   39.,   39.,   39.,   40.,   40.,   41.,\n",
       "          42.,   43.,   44.,   45.,   45.,   45.,   45.,   46.,   47.,\n",
       "          48.,   48.,   49.,   49.,   49.,   50.,   51.,   51.,   52.,\n",
       "          52.,   52.,   52.,   53.,   54.,   54.,   54.,   55.,   55.,\n",
       "          56.,   57.,   57.,   57.,   58.,   58.,   58.,   58.,   58.,\n",
       "          58.,   58.,   58.,   58.,   58.,   59.,   59.,   60.,   60.,\n",
       "          60.,   60.,   61.,   62.,   63.,   64.,   64.,   64.,   64.,\n",
       "          64.,   65.,   65.,   65.,   65.,   66.,   66.,   67.,   67.,\n",
       "          68.,   69.,   69.,   70.,   70.,   70.,   70.,   70.,   71.,\n",
       "          71.,   72.,   72.,   72.,   72.,   72.,   73.,   74.,   74.,\n",
       "          75.,   75.,   76.,   76.,   77.,   77.,   78.,   78.,   79.,\n",
       "          79.,   79.,   79.,   79.,   79.,   79.,   79.,   80.,   80.,\n",
       "          80.,   80.,   80.,   80.,   81.,   82.,   83.,   83.,   84.,\n",
       "          85.,   86.,   86.,   86.,   86.,   87.,   87.,   87.,   87.,\n",
       "          87.,   87.,   88.,   88.,   89.,   89.,   89.,   90.,   90.,\n",
       "          91.,   92.,   92.,   93.,   93.,   94.,   95.,   95.,   96.,\n",
       "          97.,   98.,   98.,   99.,   99.,   99.,   99.,  100.,  100.,\n",
       "         100.,  101.,  101.,  101.,  102.,  102.,  102.,  102.,  102.,\n",
       "         102.,  103.,  104.,  105.,  106.,  106.,  106.,  106.,  106.,\n",
       "         106.,  106.,  106.,  106.,  106.,  107.,  107.,  108.,  109.,\n",
       "         110.,  111.,  111.,  112.,  113.,  113.,  114.,  115.,  115.,\n",
       "         115.,  115.,  116.,  117.,  118.,  119.,  120.,  121.,  121.,\n",
       "         122.,  123.,  123.,  123.,  123.,  123.,  123.,  123.,  123.,\n",
       "         123.,  123.,  123.,  123.,  123.,  123.,  123.,  123.,  123.,\n",
       "         123.,  123.,  123.,  123.,  123.,  123.,  123.,  124.,  124.,\n",
       "         124.,  124.,  125.,  126.,  127.,  127.,  128.,  129.,  130.,\n",
       "         130.,  131.,  132.,  133.,  133.,  133.,  133.,  134.,  134.,\n",
       "         134.,  134.,  134.,  135.,  135.,  135.,  135.,  136.,  136.,\n",
       "         137.,  138.,  139.,  139.,  139.,  140.,  140.,  141.,  141.,\n",
       "         141.,  141.,  141.,  141.,  141.,  141.,  142.,  142.,  143.,\n",
       "         144.,  145.,  145.,  145.,  145.,  145.,  145.,  145.,  145.,\n",
       "         145.,  146.,  146.,  146.,  146.,  146.,  146.,  147.,  148.,\n",
       "         148.,  148.,  149.,  150.,  151.,  151.,  151.,  151.,  151.,\n",
       "         151.,  152.,  152.,  152.,  152.,  152.,  152.,  153.,  153.,\n",
       "         153.,  153.,  154.,  155.,  155.,  156.,  157.,  157.,  157.,\n",
       "         157.,  157.,  158.,  159.,  159.,  159.,  160.,  160.,  160.,\n",
       "         160.,  160.,  161.,  161.,  162.,  163.,  164.,  164.,  164.,\n",
       "         164.]])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 3.,  3.,  3.]),\n",
       " array([ 3.,  3.,  3.]),\n",
       " array([ 3.]),\n",
       " array([ 3.]),\n",
       " array([ 3.]),\n",
       " array([ 3.]),\n",
       " array([ 3.]),\n",
       " array([ 3.]),\n",
       " array([ 3.,  3.,  3.]),\n",
       " array([ 2.,  2.,  2.]),\n",
       " array([ 2.,  2.,  1.,  1.]),\n",
       " array([ 1.,  1.]),\n",
       " array([ 1.]),\n",
       " array([ 2.,  2.,  2.]),\n",
       " array([ 2.,  2.,  2.,  2.,  1.,  1.,  1.]),\n",
       " array([ 1.]),\n",
       " array([ 1.,  1.]),\n",
       " array([ 3.]),\n",
       " array([ 3.]),\n",
       " array([ 3.,  3.,  3.]),\n",
       " array([ 3.,  5.,  5.,  5.]),\n",
       " array([ 8.]),\n",
       " array([ 8.]),\n",
       " array([ 8.,  8.]),\n",
       " array([ 6.]),\n",
       " array([ 6.,  6.,  5.,  5.]),\n",
       " array([ 5.]),\n",
       " array([ 5.]),\n",
       " array([ 5.]),\n",
       " array([ 5.,  5.]),\n",
       " array([ 6.,  6.,  7.,  7.,  7.,  7.]),\n",
       " array([ 9.,  9.]),\n",
       " array([ 9.]),\n",
       " array([ 8.,  6.]),\n",
       " array([ 6.,  6.]),\n",
       " array([ 6.,  6.]),\n",
       " array([ 6.]),\n",
       " array([ 6.]),\n",
       " array([ 6.,  6.,  6.,  7.,  8.]),\n",
       " array([ 8.,  8.,  8.,  7.]),\n",
       " array([ 7.,  7.]),\n",
       " array([ 8.]),\n",
       " array([ 8.]),\n",
       " array([ 8.]),\n",
       " array([ 8.]),\n",
       " array([ 7.,  6.,  6.,  6.]),\n",
       " array([ 6.]),\n",
       " array([ 6.]),\n",
       " array([ 6.,  6.]),\n",
       " array([ 6.,  6.,  4.]),\n",
       " array([ 3.]),\n",
       " array([ 3.,  3.]),\n",
       " array([ 3.,  3.,  3.,  3.]),\n",
       " array([ 3.]),\n",
       " array([ 3.,  3.,  3.]),\n",
       " array([ 3.,  3.]),\n",
       " array([ 3.]),\n",
       " array([ 3.,  2.,  2.]),\n",
       " array([ 2.,  2.,  2.,  2.,  2.,  1.,  1.,  1.,  2.,  1.]),\n",
       " array([ 1.,  3.]),\n",
       " array([ 3.,  3.,  3.,  3.]),\n",
       " array([ 8.]),\n",
       " array([ 8.]),\n",
       " array([ 8.]),\n",
       " array([ 8.,  8.,  8.,  8.,  8.]),\n",
       " array([ 8.,  8.,  8.,  8.]),\n",
       " array([ 4.,  4.]),\n",
       " array([ 4.,  4.]),\n",
       " array([ 6.]),\n",
       " array([ 6.,  6.]),\n",
       " array([ 6.,  4.,  3.,  3.,  2.]),\n",
       " array([ 2.,  2.]),\n",
       " array([ 2.,  2.,  3.,  3.,  3.]),\n",
       " array([ 3.]),\n",
       " array([ 3.,  3.]),\n",
       " array([ 3.,  2.]),\n",
       " array([ 2.,  2.]),\n",
       " array([ 2.,  2.]),\n",
       " array([ 3.,  3.]),\n",
       " array([ 3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.]),\n",
       " array([ 8.,  8.,  8.,  8.,  8.,  8.]),\n",
       " array([ 8.]),\n",
       " array([ 8.]),\n",
       " array([ 8.,  8.]),\n",
       " array([ 6.]),\n",
       " array([ 6.]),\n",
       " array([ 6.,  6.,  6.,  6.]),\n",
       " array([ 6.,  3.,  3.,  2.,  2.,  2.]),\n",
       " array([ 2.,  2.]),\n",
       " array([ 2.,  2.,  2.]),\n",
       " array([ 2.,  2.]),\n",
       " array([ 2.]),\n",
       " array([ 2.,  2.]),\n",
       " array([ 3.,  2.]),\n",
       " array([ 2.]),\n",
       " array([ 2.,  2.]),\n",
       " array([ 2.]),\n",
       " array([ 2.]),\n",
       " array([ 2.,  2.]),\n",
       " array([ 2.,  3.,  5.,  8.]),\n",
       " array([ 8.,  8.,  8.]),\n",
       " array([ 8.,  8.,  8.]),\n",
       " array([ 8.,  8.,  8.,  8.,  2.,  2.]),\n",
       " array([ 2.]),\n",
       " array([ 2.]),\n",
       " array([ 2.]),\n",
       " array([ 2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]),\n",
       " array([ 2.,  2.]),\n",
       " array([ 2.]),\n",
       " array([ 2.]),\n",
       " array([ 3.]),\n",
       " array([ 3.,  3.]),\n",
       " array([ 3.]),\n",
       " array([ 3.,  8.]),\n",
       " array([ 8.]),\n",
       " array([ 8.,  8.,  8.,  6.]),\n",
       " array([ 5.]),\n",
       " array([ 5.]),\n",
       " array([ 5.]),\n",
       " array([ 4.]),\n",
       " array([ 3.]),\n",
       " array([ 3.,  3.]),\n",
       " array([ 3.]),\n",
       " array([ 3.,  3.,  3.,  3.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,\n",
       "         8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  8.,  7.,  8.]),\n",
       " array([ 7.,  7.,  7.,  7.]),\n",
       " array([ 5.]),\n",
       " array([ 5.]),\n",
       " array([ 5.,  6.]),\n",
       " array([ 6.]),\n",
       " array([ 7.]),\n",
       " array([ 7.,  7.]),\n",
       " array([ 7.]),\n",
       " array([ 7.]),\n",
       " array([ 6.,  6.,  3.,  3.]),\n",
       " array([ 3.,  3.,  3.,  3.,  3.]),\n",
       " array([ 3.,  3.,  3.,  3.]),\n",
       " array([ 3.,  3.]),\n",
       " array([ 3.]),\n",
       " array([ 3.]),\n",
       " array([ 3.,  3.,  3.]),\n",
       " array([ 3.,  3.]),\n",
       " array([ 3.,  2.,  2.,  2.,  2.,  2.,  2.,  2.]),\n",
       " array([ 2.,  2.]),\n",
       " array([ 2.]),\n",
       " array([ 2.]),\n",
       " array([ 2.,  2.,  2.,  3.,  3.,  3.,  8.,  8.,  8.]),\n",
       " array([ 8.,  8.,  8.,  8.,  5.,  5.]),\n",
       " array([ 5.]),\n",
       " array([ 5.,  5.,  5.]),\n",
       " array([ 5.]),\n",
       " array([ 6.]),\n",
       " array([ 6.,  6.,  6.,  5.,  5.,  5.]),\n",
       " array([ 5.,  5.,  5.,  5.,  5.,  5.]),\n",
       " array([ 5.,  5.,  5.,  5.]),\n",
       " array([ 5.]),\n",
       " array([ 5.,  5.]),\n",
       " array([ 5.]),\n",
       " array([ 6.,  6.,  6.,  6.,  8.]),\n",
       " array([ 8.]),\n",
       " array([ 8.,  8.,  8.]),\n",
       " array([ 5.,  5.,  5.,  5.,  5.]),\n",
       " array([ 5.,  5.]),\n",
       " array([ 5.]),\n",
       " array([ 5.]),\n",
       " array([ 5.,  5.,  5.,  5.])]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = np.zeros(shape=(len(np.unique(new_seg)),))\n",
    "segs = np.unique(new_seg)\n",
    "pack  = [np.where(new_seg==segs[i]) for i in range(len(segs))]\n",
    "predict_pack = [compare[0][pack[i]] for i in range(len(segs))]\n",
    "predict_pack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def normpdf(x, mean, sd):\n",
    "    var = sd**2\n",
    "    pi = 3.1415926\n",
    "    denom = (2*pi*var)**.5\n",
    "    num = np.exp((-x-mean)**2/(2*var))\n",
    "    return num/denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "2.0\n",
      "5.0\n",
      "5.0\n",
      "7.0\n",
      "6.0\n",
      "6.0\n",
      "8.0\n",
      "6.0\n",
      "6.0\n",
      "2.0\n",
      "2.0\n",
      "1.0\n",
      "3.0\n",
      "3.0\n",
      "2.0\n",
      "8.0\n",
      "2.0\n",
      "2.0\n",
      "2.0\n",
      "8.0\n",
      "3.0\n",
      "8.0\n",
      "8.0\n",
      "5.0\n",
      "3.0\n",
      "2.0\n",
      "2.0\n",
      "8.0\n",
      "5.0\n",
      "6.0\n",
      "[ 3.  3.  3.  3.  3.  3.  3.  3.  3.  2.  1.  1.  1.  2.  2.  1.  1.  3.\n",
      "  3.  3.  5.  8.  8.  8.  6.  5.  5.  5.  5.  5.  7.  9.  9.  6.  6.  6.\n",
      "  6.  6.  6.  8.  7.  8.  8.  8.  8.  6.  6.  6.  6.  6.  3.  3.  3.  3.\n",
      "  3.  3.  3.  2.  2.  1.  3.  8.  8.  8.  8.  8.  4.  4.  6.  6.  3.  2.\n",
      "  3.  3.  3.  2.  2.  2.  3.  8.  8.  8.  8.  8.  6.  6.  6.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  8.  8.  8.  2.  2.  2.  2.  2.\n",
      "  2.  2.  3.  3.  3.  3.  8.  8.  5.  5.  5.  4.  3.  3.  3.  8.  7.  5.\n",
      "  5.  5.  6.  7.  7.  7.  7.  3.  3.  3.  3.  3.  3.  3.  3.  2.  2.  2.\n",
      "  2.  2.  8.  5.  5.  5.  6.  5.  5.  5.  5.  5.  5.  6.  8.  8.  5.  5.\n",
      "  5.  5.  5.]\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "L = np.zeros(shape = (len(predict_pack),))\n",
    "for i in range(len(predict_pack)):\n",
    "    n = predict_pack[i]\n",
    "    if len(np.unique(n))!= 1:\n",
    "        L[i]=np.argmax(np.bincount(np.int_(n)))\n",
    "        print(L[i])\n",
    "    else:\n",
    "        L[i] = predict_pack[i][0]\n",
    "    \n",
    "print(L)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def litho(L, label):\n",
    "    count = 0\n",
    "    new = np.zeros(shape=(len(label),))\n",
    "    for i in range(0, len(label)-1):\n",
    "        if i == 0:\n",
    "            new[i] = L[count]\n",
    "        elif label[i] == label[i-1]:\n",
    "            new[i] = L[count]\n",
    "        elif label[i] != label[i-1]:\n",
    "            count = count+1\n",
    "            new[i] = L[count]            \n",
    "    new[-1] = L[-1] \n",
    "    return new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  2.  2.  2.\n",
      "  1.  1.  1.  1.  1.  1.  1.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  1.\n",
      "  1.  1.  3.  3.  3.  3.  3.  5.  5.  5.  5.  8.  8.  8.  8.  6.  5.  5.\n",
      "  5.  5.  5.  5.  5.  5.  5.  7.  7.  7.  7.  7.  7.  9.  9.  9.  6.  6.\n",
      "  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  8.  8.  8.  8.  7.  7.  8.\n",
      "  8.  8.  8.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  6.  3.  3.  3.  3.\n",
      "  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  1.  1.  3.  3.  3.  3.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  4.  4.  4.  4.  6.  6.  6.  3.  3.  3.  3.  3.  2.\n",
      "  2.  3.  3.  3.  3.  3.  3.  3.  3.  2.  2.  2.  2.  2.  2.  3.  3.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  6.\n",
      "  6.  6.  6.  6.  6.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  3.  3.  3.  3.  3.  3.  8.  8.  8.\n",
      "  8.  8.  5.  5.  5.  4.  3.  3.  3.  3.  8.  8.  8.  8.  8.  8.  8.  8.\n",
      "  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  8.  7.  7.\n",
      "  7.  7.  5.  5.  5.  5.  6.  7.  7.  7.  7.  7.  3.  3.  3.  3.  3.  3.\n",
      "  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  3.  2.  2.\n",
      "  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.\n",
      "  2.  8.  8.  8.  8.  8.  8.  5.  5.  5.  5.  5.  6.  5.  5.  5.  5.  5.\n",
      "  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  6.  6.  6.\n",
      "  6.  6.  8.  8.  8.  8.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.  5.\n",
      "  5.]\n",
      "[3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 2 2 2 2 1 1 1 1 1 2 2 2 2 2 2 2 1 1 1 1 1\n",
      " 1 3 3 3 3 3 3 5 5 5 8 8 8 8 6 6 6 5 5 5 5 5 5 5 6 6 7 7 7 7 9 9 9 8 6 6 6\n",
      " 6 6 6 6 6 6 6 7 8 8 8 8 7 7 7 8 8 8 8 7 6 6 6 6 6 6 6 6 6 4 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 1 1 1 2 1 1 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 4 4 4 4 6 6 6 6 4 3 3 2 2 2 2 2 3 3 3 3 3 3 3 2 2 2 2 2 3 3 3 8 8 8 8 8\n",
      " 8 8 8 8 8 8 8 8 8 8 8 8 6 6 6 6 6 6 6 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2\n",
      " 2 2 2 2 2 2 2 3 5 8 8 8 8 8 8 8 8 8 8 8 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 3 3 3 3 3 8 8 8 8 8 6 5 5 5 4 3 3 3 3 3 3 3 3 8 8 8 8 8 8 8 8 8 8 8 8\n",
      " 8 8 8 8 8 8 7 8 7 7 7 7 5 5 5 6 6 7 7 7 7 7 6 6 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 8 8 8 8 8 8 8 5 5 5 5 5\n",
      " 5 5 6 6 6 6 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 6 6 6 6 8 8 8 8 8 5 5 5 5 5\n",
      " 5 5 5 5 5 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "new = litho(L, new_seg)\n",
    "print(new)\n",
    "print(predict_facie.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict_facie = pd.read_csv(\"Prediction_XX_Final.csv\")[\"Facies\"]\n",
    "test_data = pd.read_csv(\"../bayseg/data/2016-ml-contest-Hall/test_data_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJQAAALhCAYAAAC5TI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20faec884e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sol = np.repeat(np.expand_dims(test_data[\"Facies\"].values, 1), 100, 1)\n",
    "ml_sol = np.repeat(np.expand_dims(new, 1), 100, 1)\n",
    "contest = np.repeat(np.expand_dims(predict_facie, 1), 100, 1)\n",
    "\n",
    "fig, ax = plt.subplots(ncols=3, sharey=True, figsize=(2,13))\n",
    "\n",
    "ax[0].imshow(sol, cmap=\"viridis\")\n",
    "ax[1].imshow(ml_sol, cmap=\"viridis\")\n",
    "ax[2].imshow(contest, cmap=\"viridis\")\n",
    "\n",
    "\n",
    "ax[0].grid(False)\n",
    "ax[1].grid(False)\n",
    "ax[2].grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 2, 2, 2, 2, 2,\n",
       "       2, 8, 8, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 4, 4, 6, 6, 4, 6, 6, 8, 8, 8,\n",
       "       6, 6, 6, 6, 6, 5, 5, 5, 5, 5, 6, 8, 8, 8, 8, 6, 6, 5, 6, 6, 6, 6, 6,\n",
       "       3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 2, 2, 2, 2, 2, 2, 3, 4, 5, 6, 6, 6,\n",
       "       6, 6, 6, 8, 8, 8, 8, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 5, 5, 5, 5, 1,\n",
       "       1, 1, 2, 1, 1, 1, 1, 1, 4, 4, 3, 3, 3, 3, 2, 2, 2, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       2, 2, 2, 3, 3, 5, 5, 8, 8, 8, 6, 6, 6, 6, 3, 2, 2, 2, 2, 3, 3, 3, 3,\n",
       "       3, 3, 3, 3, 3, 3, 3, 3, 3, 5, 5, 3, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8,\n",
       "       8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 5, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
       "       3, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 5, 8, 8, 8, 8, 6, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 5, 5,\n",
       "       5, 5, 5, 5, 5, 5, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 4, 4, 6, 6,\n",
       "       8, 8, 8, 8, 6, 5, 5, 8, 2, 2, 3, 2, 3, 3, 3, 8, 8, 8], dtype=int64)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[\"Facies\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3972055888223553\n",
      "0.3772455089820359\n"
     ]
    }
   ],
   "source": [
    "print(np.count_nonzero(sol[:,1]-ml_sol[:,1])/len(test_data))\n",
    "print(np.count_nonzero(sol[:,1]-contest[:,1])/len(test_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " data[data[\"Well Name\"] == \"CHURCHMAN BIBLE\"]\n",
    "    np.where(data[\"Well Name\"] == \"CHURCHMAN BIBLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
